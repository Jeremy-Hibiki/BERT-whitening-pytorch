2023-08-22 03:00:18,366 : BgeBase-whiten-768(NLI)-cls configs: {'encoder': './model/bge-base-zh', 'pooling': 'cls', 'whiten_file': './whiten/bge-base-zh-cls-whiten(NLI).pkl', 'n_components': 768}
2023-08-22 03:00:24,909 : Building ./model/bge-base-zh tokenizer and model successfuly.
2023-08-22 03:00:24,920 : Loading kernel and bias from ./whiten/bge-base-zh-cls-whiten(NLI).pkl
2023-08-22 03:00:24,920 : ***** Transfer task : STS12 *****


2023-08-22 03:00:36,658 : MSRpar : pearson = 0.4681, spearman = 0.4797
2023-08-22 03:00:47,203 : MSRvid : pearson = 0.8238, spearman = 0.8263
2023-08-22 03:00:53,657 : SMTeuroparl : pearson = 0.5185, spearman = 0.6001
2023-08-22 03:01:04,148 : surprise.OnWN : pearson = 0.6571, spearman = 0.6486
2023-08-22 03:01:09,808 : surprise.SMTnews : pearson = 0.5408, spearman = 0.5446
2023-08-22 03:01:09,808 : ALL (weighted average) : Pearson = 0.6163,             Spearman = 0.6302
2023-08-22 03:01:09,808 : ALL (average) : Pearson = 0.6017,             Spearman = 0.6199

2023-08-22 03:01:09,808 : ***** Transfer task : STS13 (-SMT) *****


2023-08-22 03:01:12,629 : FNWN : pearson = 0.4071, spearman = 0.4299
2023-08-22 03:01:23,181 : headlines : pearson = 0.7546, spearman = 0.7445
2023-08-22 03:01:31,187 : OnWN : pearson = 0.5390, spearman = 0.5386
2023-08-22 03:01:31,187 : ALL (weighted average) : Pearson = 0.6302,             Spearman = 0.6278
2023-08-22 03:01:31,187 : ALL (average) : Pearson = 0.5669,             Spearman = 0.5710

2023-08-22 03:01:31,187 : ***** Transfer task : STS14 *****


2023-08-22 03:01:38,276 : deft-forum : pearson = 0.5062, spearman = 0.5021
2023-08-22 03:01:42,621 : deft-news : pearson = 0.7515, spearman = 0.7015
2023-08-22 03:01:53,389 : headlines : pearson = 0.7137, spearman = 0.6840
2023-08-22 03:02:04,549 : images : pearson = 0.7885, spearman = 0.7766
2023-08-22 03:02:15,184 : OnWN : pearson = 0.6660, spearman = 0.6999
2023-08-22 03:02:25,858 : tweet-news : pearson = 0.7579, spearman = 0.7051
2023-08-22 03:02:25,859 : ALL (weighted average) : Pearson = 0.7061,             Spearman = 0.6895
2023-08-22 03:02:25,859 : ALL (average) : Pearson = 0.6973,             Spearman = 0.6782

2023-08-22 03:02:25,859 : ***** Transfer task : STS15 *****


2023-08-22 03:02:31,229 : answers-forums : pearson = 0.6949, spearman = 0.6850
2023-08-22 03:02:41,800 : answers-students : pearson = 0.7799, spearman = 0.7812
2023-08-22 03:02:47,127 : belief : pearson = 0.7593, spearman = 0.7716
2023-08-22 03:02:57,746 : headlines : pearson = 0.7702, spearman = 0.7678
2023-08-22 03:03:08,402 : images : pearson = 0.8334, spearman = 0.8461
2023-08-22 03:03:08,402 : ALL (weighted average) : Pearson = 0.7776,             Spearman = 0.7808
2023-08-22 03:03:08,402 : ALL (average) : Pearson = 0.7675,             Spearman = 0.7703

2023-08-22 03:03:08,402 : ***** Transfer task : STS16 *****


2023-08-22 03:03:11,996 : answer-answer : pearson = 0.6250, spearman = 0.6104
2023-08-22 03:03:15,557 : headlines : pearson = 0.7634, spearman = 0.7633
2023-08-22 03:03:18,833 : plagiarism : pearson = 0.8173, spearman = 0.8214
2023-08-22 03:03:22,379 : postediting : pearson = 0.8551, spearman = 0.8580
2023-08-22 03:03:25,380 : question-question : pearson = 0.5635, spearman = 0.5562
2023-08-22 03:03:25,380 : ALL (weighted average) : Pearson = 0.7278,             Spearman = 0.7248
2023-08-22 03:03:25,380 : ALL (average) : Pearson = 0.7249,             Spearman = 0.7219

2023-08-22 03:03:25,380 : 

***** Transfer task : STSBenchmark*****


2023-08-22 03:03:25,407 : Computing embedding for test
2023-08-22 03:03:44,770 : Computed test embeddings
2023-08-22 03:03:44,827 : Test : Pearson 0.7233907495505859 Spearman 0.7121870903993496 MSE 6.383450723846224

2023-08-22 03:03:44,828 : ***** Transfer task : SICK-Relatedness*****


2023-08-22 03:03:44,856 : Computing embedding for test
2023-08-22 03:04:53,735 : Computed test embeddings
2023-08-22 03:04:53,951 : Test : Pearson 0.6704556005663136 Spearman 0.6355439728789036 MSE 9.781255410778986

2023-08-22 03:04:53,953 : BgeBase-whiten-768(NLI)-cls results:
+----------------------+--------------------+
|         Task         |      Spearman      |
+----------------------+--------------------+
|        STS12         | 0.6302141504632974 |
|        STS13         | 0.6278442125646673 |
|        STS14         | 0.6895068835949908 |
|        STS15         | 0.7808461824498035 |
|        STS16         | 0.7248068881466982 |
|  STSBenchmarkCosin   | 0.7121870903993496 |
| SICKRelatednessCosin | 0.6355439728789036 |
+----------------------+--------------------+
2023-08-22 03:04:53,960 : BgeBase-whiten-256(NLI)-cls configs: {'encoder': './model/bge-base-zh', 'pooling': 'cls', 'whiten_file': './whiten/bge-base-zh-cls-whiten(NLI).pkl', 'n_components': 256}
2023-08-22 03:04:54,621 : Building ./model/bge-base-zh tokenizer and model successfuly.
2023-08-22 03:04:54,622 : Loading kernel and bias from ./whiten/bge-base-zh-cls-whiten(NLI).pkl
2023-08-22 03:04:54,622 : ***** Transfer task : STS12 *****


2023-08-22 03:05:06,143 : MSRpar : pearson = 0.4673, spearman = 0.4809
2023-08-22 03:05:16,896 : MSRvid : pearson = 0.8454, spearman = 0.8387
2023-08-22 03:05:23,358 : SMTeuroparl : pearson = 0.5262, spearman = 0.5949
2023-08-22 03:05:33,855 : surprise.OnWN : pearson = 0.6815, spearman = 0.6669
2023-08-22 03:05:39,501 : surprise.SMTnews : pearson = 0.5246, spearman = 0.5476
2023-08-22 03:05:39,502 : ALL (weighted average) : Pearson = 0.6263,             Spearman = 0.6375
2023-08-22 03:05:39,502 : ALL (average) : Pearson = 0.6090,             Spearman = 0.6258

2023-08-22 03:05:39,502 : ***** Transfer task : STS13 (-SMT) *****


2023-08-22 03:05:42,308 : FNWN : pearson = 0.4194, spearman = 0.4613
2023-08-22 03:05:52,930 : headlines : pearson = 0.7553, spearman = 0.7463
2023-08-22 03:06:00,684 : OnWN : pearson = 0.5744, spearman = 0.5782
2023-08-22 03:06:00,685 : ALL (weighted average) : Pearson = 0.6453,             Spearman = 0.6475
2023-08-22 03:06:00,685 : ALL (average) : Pearson = 0.5830,             Spearman = 0.5953

2023-08-22 03:06:00,685 : ***** Transfer task : STS14 *****


2023-08-22 03:06:07,009 : deft-forum : pearson = 0.5196, spearman = 0.5180
2023-08-22 03:06:11,341 : deft-news : pearson = 0.7519, spearman = 0.7062
2023-08-22 03:06:21,880 : headlines : pearson = 0.7306, spearman = 0.6952
2023-08-22 03:06:32,541 : images : pearson = 0.8103, spearman = 0.7823
2023-08-22 03:06:43,079 : OnWN : pearson = 0.6943, spearman = 0.7249
2023-08-22 03:06:53,655 : tweet-news : pearson = 0.7641, spearman = 0.6930
2023-08-22 03:06:53,655 : ALL (weighted average) : Pearson = 0.7224,             Spearman = 0.6977
2023-08-22 03:06:53,655 : ALL (average) : Pearson = 0.7118,             Spearman = 0.6866

2023-08-22 03:06:53,655 : ***** Transfer task : STS15 *****


2023-08-22 03:06:58,933 : answers-forums : pearson = 0.6871, spearman = 0.6812
2023-08-22 03:07:09,333 : answers-students : pearson = 0.7714, spearman = 0.7803
2023-08-22 03:07:14,596 : belief : pearson = 0.7617, spearman = 0.7689
2023-08-22 03:07:25,018 : headlines : pearson = 0.7828, spearman = 0.7786
2023-08-22 03:07:35,582 : images : pearson = 0.8532, spearman = 0.8552
2023-08-22 03:07:35,582 : ALL (weighted average) : Pearson = 0.7830,             Spearman = 0.7848
2023-08-22 03:07:35,582 : ALL (average) : Pearson = 0.7713,             Spearman = 0.7728

2023-08-22 03:07:35,582 : ***** Transfer task : STS16 *****


2023-08-22 03:07:39,170 : answer-answer : pearson = 0.6250, spearman = 0.6136
2023-08-22 03:07:42,650 : headlines : pearson = 0.7550, spearman = 0.7618
2023-08-22 03:07:45,928 : plagiarism : pearson = 0.7995, spearman = 0.8017
2023-08-22 03:07:49,384 : postediting : pearson = 0.8392, spearman = 0.8527
2023-08-22 03:07:52,347 : question-question : pearson = 0.6601, spearman = 0.6632
2023-08-22 03:07:52,348 : ALL (weighted average) : Pearson = 0.7364,             Spearman = 0.7391
2023-08-22 03:07:52,348 : ALL (average) : Pearson = 0.7357,             Spearman = 0.7386

2023-08-22 03:07:52,348 : 

***** Transfer task : STSBenchmark*****


2023-08-22 03:07:52,426 : Computing embedding for test
2023-08-22 03:08:11,483 : Computed test embeddings
2023-08-22 03:08:11,536 : Test : Pearson 0.7278066966017047 Spearman 0.712020351511418 MSE 6.1736978036607795

2023-08-22 03:08:11,536 : ***** Transfer task : SICK-Relatedness*****


2023-08-22 03:08:11,557 : Computing embedding for test
2023-08-22 03:09:19,354 : Computed test embeddings
2023-08-22 03:09:19,547 : Test : Pearson 0.6846590276382972 Spearman 0.6268031011875809 MSE 9.501456137283464

2023-08-22 03:09:19,548 : BgeBase-whiten-256(NLI)-cls results:
+----------------------+--------------------+
|         Task         |      Spearman      |
+----------------------+--------------------+
|        STS12         | 0.6375158911394257 |
|        STS13         | 0.6475289460541466 |
|        STS14         | 0.6977346477559431 |
|        STS15         | 0.7847822702752872 |
|        STS16         | 0.7390955784986738 |
|  STSBenchmarkCosin   | 0.712020351511418  |
| SICKRelatednessCosin | 0.6268031011875809 |
+----------------------+--------------------+
2023-08-22 03:09:19,554 : BgeBase-whiten-768(NLI)-first_last_avg configs: {'encoder': './model/bge-base-zh', 'pooling': 'first_last_avg', 'whiten_file': './whiten/bge-base-zh-first_last_avg-whiten(NLI).pkl', 'n_components': 768}
2023-08-22 03:09:20,220 : Building ./model/bge-base-zh tokenizer and model successfuly.
2023-08-22 03:09:20,233 : Loading kernel and bias from ./whiten/bge-base-zh-first_last_avg-whiten(NLI).pkl
2023-08-22 03:09:20,233 : ***** Transfer task : STS12 *****


2023-08-22 03:09:31,009 : MSRpar : pearson = 0.4018, spearman = 0.4405
2023-08-22 03:09:41,383 : MSRvid : pearson = 0.8265, spearman = 0.8279
2023-08-22 03:09:47,822 : SMTeuroparl : pearson = 0.5105, spearman = 0.5971
2023-08-22 03:09:58,151 : surprise.OnWN : pearson = 0.6752, spearman = 0.6623
2023-08-22 03:10:03,708 : surprise.SMTnews : pearson = 0.5475, spearman = 0.5545
2023-08-22 03:10:03,708 : ALL (weighted average) : Pearson = 0.6050,             Spearman = 0.6253
2023-08-22 03:10:03,708 : ALL (average) : Pearson = 0.5923,             Spearman = 0.6165

2023-08-22 03:10:03,709 : ***** Transfer task : STS13 (-SMT) *****


2023-08-22 03:10:06,465 : FNWN : pearson = 0.4087, spearman = 0.4504
2023-08-22 03:10:16,919 : headlines : pearson = 0.7293, spearman = 0.7177
2023-08-22 03:10:24,686 : OnWN : pearson = 0.6294, spearman = 0.6221
2023-08-22 03:10:24,686 : ALL (weighted average) : Pearson = 0.6515,             Spearman = 0.6483
2023-08-22 03:10:24,686 : ALL (average) : Pearson = 0.5891,             Spearman = 0.5967

2023-08-22 03:10:24,686 : ***** Transfer task : STS14 *****


2023-08-22 03:10:30,943 : deft-forum : pearson = 0.5301, spearman = 0.5191
2023-08-22 03:10:35,203 : deft-news : pearson = 0.7507, spearman = 0.6975
2023-08-22 03:10:45,609 : headlines : pearson = 0.6976, spearman = 0.6577
2023-08-22 03:10:56,111 : images : pearson = 0.7838, spearman = 0.7754
2023-08-22 03:11:06,623 : OnWN : pearson = 0.7211, spearman = 0.7476
2023-08-22 03:11:17,895 : tweet-news : pearson = 0.7669, spearman = 0.7083
2023-08-22 03:11:17,895 : ALL (weighted average) : Pearson = 0.7175,             Spearman = 0.6959
2023-08-22 03:11:17,895 : ALL (average) : Pearson = 0.7084,             Spearman = 0.6843

2023-08-22 03:11:17,895 : ***** Transfer task : STS15 *****


2023-08-22 03:11:23,257 : answers-forums : pearson = 0.6836, spearman = 0.6802
2023-08-22 03:11:33,668 : answers-students : pearson = 0.7709, spearman = 0.7702
2023-08-22 03:11:39,006 : belief : pearson = 0.7553, spearman = 0.7684
2023-08-22 03:11:49,394 : headlines : pearson = 0.7659, spearman = 0.7609
2023-08-22 03:11:59,855 : images : pearson = 0.8305, spearman = 0.8425
2023-08-22 03:11:59,855 : ALL (weighted average) : Pearson = 0.7717,             Spearman = 0.7745
2023-08-22 03:11:59,855 : ALL (average) : Pearson = 0.7612,             Spearman = 0.7644

2023-08-22 03:11:59,855 : ***** Transfer task : STS16 *****


2023-08-22 03:12:03,400 : answer-answer : pearson = 0.6456, spearman = 0.6319
2023-08-22 03:12:06,843 : headlines : pearson = 0.7668, spearman = 0.7650
2023-08-22 03:12:10,077 : plagiarism : pearson = 0.8294, spearman = 0.8362
2023-08-22 03:12:13,546 : postediting : pearson = 0.8653, spearman = 0.8660
2023-08-22 03:12:16,535 : question-question : pearson = 0.5742, spearman = 0.5617
2023-08-22 03:12:16,535 : ALL (weighted average) : Pearson = 0.7393,             Spearman = 0.7353
2023-08-22 03:12:16,535 : ALL (average) : Pearson = 0.7363,             Spearman = 0.7322

2023-08-22 03:12:16,535 : 

***** Transfer task : STSBenchmark*****


2023-08-22 03:12:16,553 : Computing embedding for test
2023-08-22 03:12:35,740 : Computed test embeddings
2023-08-22 03:12:35,812 : Test : Pearson 0.7114830943048577 Spearman 0.6963119947050375 MSE 6.487309489118746

2023-08-22 03:12:35,812 : ***** Transfer task : SICK-Relatedness*****


2023-08-22 03:12:35,836 : Computing embedding for test
2023-08-22 03:13:44,430 : Computed test embeddings
2023-08-22 03:13:44,663 : Test : Pearson 0.6555815696087319 Spearman 0.6186285862557326 MSE 9.969026901534345

2023-08-22 03:13:44,666 : BgeBase-whiten-768(NLI)-first_last_avg results:
+----------------------+--------------------+
|         Task         |      Spearman      |
+----------------------+--------------------+
|        STS12         | 0.6252746139793516 |
|        STS13         | 0.6482666130480562 |
|        STS14         | 0.695884184525077  |
|        STS15         | 0.7744688586004743 |
|        STS16         | 0.7352607713596033 |
|  STSBenchmarkCosin   | 0.6963119947050375 |
| SICKRelatednessCosin | 0.6186285862557326 |
+----------------------+--------------------+
2023-08-22 03:13:44,673 : BgeBase-whiten-256(NLI)-first_last_avg configs: {'encoder': './model/bge-base-zh', 'pooling': 'first_last_avg', 'whiten_file': './whiten/bge-base-zh-first_last_avg-whiten(NLI).pkl', 'n_components': 256}
2023-08-22 03:13:45,403 : Building ./model/bge-base-zh tokenizer and model successfuly.
2023-08-22 03:13:45,404 : Loading kernel and bias from ./whiten/bge-base-zh-first_last_avg-whiten(NLI).pkl
2023-08-22 03:13:45,404 : ***** Transfer task : STS12 *****


2023-08-22 03:13:56,262 : MSRpar : pearson = 0.4026, spearman = 0.4428
2023-08-22 03:14:06,596 : MSRvid : pearson = 0.8486, spearman = 0.8429
2023-08-22 03:14:12,959 : SMTeuroparl : pearson = 0.5217, spearman = 0.5954
2023-08-22 03:14:23,614 : surprise.OnWN : pearson = 0.6937, spearman = 0.6766
2023-08-22 03:14:32,531 : surprise.SMTnews : pearson = 0.5834, spearman = 0.5987
2023-08-22 03:14:32,531 : ALL (weighted average) : Pearson = 0.6213,             Spearman = 0.6383
2023-08-22 03:14:32,531 : ALL (average) : Pearson = 0.6100,             Spearman = 0.6313

2023-08-22 03:14:32,531 : ***** Transfer task : STS13 (-SMT) *****


2023-08-22 03:14:36,518 : FNWN : pearson = 0.4100, spearman = 0.4527
2023-08-22 03:14:49,080 : headlines : pearson = 0.7427, spearman = 0.7331
2023-08-22 03:14:56,655 : OnWN : pearson = 0.6449, spearman = 0.6395
2023-08-22 03:14:56,655 : ALL (weighted average) : Pearson = 0.6642,             Spearman = 0.6628
2023-08-22 03:14:56,655 : ALL (average) : Pearson = 0.5992,             Spearman = 0.6084

2023-08-22 03:14:56,655 : ***** Transfer task : STS14 *****


2023-08-22 03:15:03,071 : deft-forum : pearson = 0.5428, spearman = 0.5305
2023-08-22 03:15:07,299 : deft-news : pearson = 0.7620, spearman = 0.7141
2023-08-22 03:15:17,646 : headlines : pearson = 0.7184, spearman = 0.6754
2023-08-22 03:15:30,015 : images : pearson = 0.8044, spearman = 0.7855
2023-08-22 03:15:42,543 : OnWN : pearson = 0.7363, spearman = 0.7638
2023-08-22 03:15:53,200 : tweet-news : pearson = 0.7904, spearman = 0.7255
2023-08-22 03:15:53,200 : ALL (weighted average) : Pearson = 0.7360,             Spearman = 0.7108
2023-08-22 03:15:53,200 : ALL (average) : Pearson = 0.7257,             Spearman = 0.6991

2023-08-22 03:15:53,200 : ***** Transfer task : STS15 *****


2023-08-22 03:15:58,700 : answers-forums : pearson = 0.6738, spearman = 0.6676
2023-08-22 03:16:09,187 : answers-students : pearson = 0.7736, spearman = 0.7788
2023-08-22 03:16:14,203 : belief : pearson = 0.7705, spearman = 0.7755
2023-08-22 03:16:24,530 : headlines : pearson = 0.7766, spearman = 0.7717
2023-08-22 03:16:34,552 : images : pearson = 0.8504, spearman = 0.8520
2023-08-22 03:16:34,552 : ALL (weighted average) : Pearson = 0.7807,             Spearman = 0.7810
2023-08-22 03:16:34,552 : ALL (average) : Pearson = 0.7690,             Spearman = 0.7691

2023-08-22 03:16:34,552 : ***** Transfer task : STS16 *****


2023-08-22 03:16:38,133 : answer-answer : pearson = 0.6163, spearman = 0.6031
2023-08-22 03:16:41,483 : headlines : pearson = 0.7505, spearman = 0.7603
2023-08-22 03:16:44,622 : plagiarism : pearson = 0.8216, spearman = 0.8284
2023-08-22 03:16:48,063 : postediting : pearson = 0.8590, spearman = 0.8665
2023-08-22 03:16:52,322 : question-question : pearson = 0.6358, spearman = 0.6300
2023-08-22 03:16:52,323 : ALL (weighted average) : Pearson = 0.7376,             Spearman = 0.7387
2023-08-22 03:16:52,323 : ALL (average) : Pearson = 0.7366,             Spearman = 0.7377

2023-08-22 03:16:52,323 : 

***** Transfer task : STSBenchmark*****


2023-08-22 03:16:52,342 : Computing embedding for test
2023-08-22 03:17:12,581 : Computed test embeddings
2023-08-22 03:17:12,634 : Test : Pearson 0.7218479166167244 Spearman 0.7056389450924111 MSE 6.182251877819297

2023-08-22 03:17:12,634 : ***** Transfer task : SICK-Relatedness*****


2023-08-22 03:17:12,660 : Computing embedding for test
2023-08-22 03:18:20,365 : Computed test embeddings
2023-08-22 03:18:20,565 : Test : Pearson 0.6841546922455544 Spearman 0.6246619298893133 MSE 9.55247626350713

2023-08-22 03:18:20,566 : BgeBase-whiten-256(NLI)-first_last_avg results:
+----------------------+--------------------+
|         Task         |      Spearman      |
+----------------------+--------------------+
|        STS12         | 0.638310950789289  |
|        STS13         | 0.6627623217557709 |
|        STS14         | 0.710838764902491  |
|        STS15         | 0.7810071523565243 |
|        STS16         | 0.7387326455537567 |
|  STSBenchmarkCosin   | 0.7056389450924111 |
| SICKRelatednessCosin | 0.6246619298893133 |
+----------------------+--------------------+
2023-08-22 03:18:20,575 : BgeLarge-whiten-1024(NLI)-cls configs: {'encoder': './model/bge-large-zh', 'pooling': 'cls', 'whiten_file': './whiten/bge-large-zh-cls-whiten(NLI).pkl', 'n_components': 1024}
2023-08-22 03:18:28,162 : Building ./model/bge-large-zh tokenizer and model successfuly.
2023-08-22 03:18:28,165 : Loading kernel and bias from ./whiten/bge-large-zh-cls-whiten(NLI).pkl
2023-08-22 03:18:28,165 : ***** Transfer task : STS12 *****


2023-08-22 03:18:47,726 : MSRpar : pearson = 0.5384, spearman = 0.5305
2023-08-22 03:19:07,335 : MSRvid : pearson = 0.7541, spearman = 0.7541
2023-08-22 03:19:19,027 : SMTeuroparl : pearson = 0.5119, spearman = 0.5862
2023-08-22 03:19:38,676 : surprise.OnWN : pearson = 0.6758, spearman = 0.6650
2023-08-22 03:19:48,896 : surprise.SMTnews : pearson = 0.5734, spearman = 0.5792
2023-08-22 03:19:48,896 : ALL (weighted average) : Pearson = 0.6242,             Spearman = 0.6314
2023-08-22 03:19:48,897 : ALL (average) : Pearson = 0.6107,             Spearman = 0.6230

2023-08-22 03:19:48,897 : ***** Transfer task : STS13 (-SMT) *****


2023-08-22 03:19:54,744 : FNWN : pearson = 0.4875, spearman = 0.5004
2023-08-22 03:20:13,880 : headlines : pearson = 0.7736, spearman = 0.7612
2023-08-22 03:20:28,446 : OnWN : pearson = 0.6001, spearman = 0.6046
2023-08-22 03:20:28,446 : ALL (weighted average) : Pearson = 0.6726,             Spearman = 0.6697
2023-08-22 03:20:28,446 : ALL (average) : Pearson = 0.6204,             Spearman = 0.6220

2023-08-22 03:20:28,447 : ***** Transfer task : STS14 *****


2023-08-22 03:20:40,095 : deft-forum : pearson = 0.5415, spearman = 0.5281
2023-08-22 03:20:48,397 : deft-news : pearson = 0.7758, spearman = 0.7427
2023-08-22 03:21:10,020 : headlines : pearson = 0.7513, spearman = 0.7155
2023-08-22 03:21:30,087 : images : pearson = 0.7711, spearman = 0.7657
2023-08-22 03:21:50,735 : OnWN : pearson = 0.7079, spearman = 0.7395
2023-08-22 03:22:11,928 : tweet-news : pearson = 0.7764, spearman = 0.7321
2023-08-22 03:22:11,928 : ALL (weighted average) : Pearson = 0.7284,             Spearman = 0.7133
2023-08-22 03:22:11,929 : ALL (average) : Pearson = 0.7206,             Spearman = 0.7039

2023-08-22 03:22:11,929 : ***** Transfer task : STS15 *****


2023-08-22 03:22:24,471 : answers-forums : pearson = 0.7353, spearman = 0.7291
2023-08-22 03:22:44,193 : answers-students : pearson = 0.8092, spearman = 0.8127
2023-08-22 03:22:53,988 : belief : pearson = 0.7416, spearman = 0.7260
2023-08-22 03:23:13,838 : headlines : pearson = 0.7961, spearman = 0.7916
2023-08-22 03:23:32,968 : images : pearson = 0.7878, spearman = 0.7956
2023-08-22 03:23:32,968 : ALL (weighted average) : Pearson = 0.7829,             Spearman = 0.7819
2023-08-22 03:23:32,968 : ALL (average) : Pearson = 0.7740,             Spearman = 0.7710

2023-08-22 03:23:32,968 : ***** Transfer task : STS16 *****


2023-08-22 03:23:39,291 : answer-answer : pearson = 0.6992, spearman = 0.6988
2023-08-22 03:23:45,754 : headlines : pearson = 0.8004, spearman = 0.8049
2023-08-22 03:23:51,816 : plagiarism : pearson = 0.8393, spearman = 0.8484
2023-08-22 03:23:58,329 : postediting : pearson = 0.8675, spearman = 0.8721
2023-08-22 03:24:03,865 : question-question : pearson = 0.6392, spearman = 0.6345
2023-08-22 03:24:03,865 : ALL (weighted average) : Pearson = 0.7717,             Spearman = 0.7744
2023-08-22 03:24:03,865 : ALL (average) : Pearson = 0.7691,             Spearman = 0.7717

2023-08-22 03:24:03,865 : 

***** Transfer task : STSBenchmark*****


2023-08-22 03:24:03,883 : Computing embedding for test
2023-08-22 03:24:42,929 : Computed test embeddings
2023-08-22 03:24:43,003 : Test : Pearson 0.6996865597735197 Spearman 0.6993445629538934 MSE 5.545117694925538

2023-08-22 03:24:43,003 : ***** Transfer task : SICK-Relatedness*****


2023-08-22 03:24:43,027 : Computing embedding for test
2023-08-22 03:26:50,372 : Computed test embeddings
2023-08-22 03:26:50,588 : Test : Pearson 0.6885219880396538 Spearman 0.6694449905712256 MSE 8.38042328979661

2023-08-22 03:26:50,589 : BgeLarge-whiten-1024(NLI)-cls results:
+----------------------+--------------------+
|         Task         |      Spearman      |
+----------------------+--------------------+
|        STS12         | 0.6313628247633374 |
|        STS13         | 0.6697450519588708 |
|        STS14         | 0.7133432071380571 |
|        STS15         | 0.7818508335187765 |
|        STS16         | 0.7744160144061815 |
|  STSBenchmarkCosin   | 0.6993445629538934 |
| SICKRelatednessCosin | 0.6694449905712256 |
+----------------------+--------------------+
2023-08-22 03:26:50,598 : BgeLarge-whiten-384(NLI)-cls configs: {'encoder': './model/bge-large-zh', 'pooling': 'cls', 'whiten_file': './whiten/bge-large-zh-cls-whiten(NLI).pkl', 'n_components': 384}
2023-08-22 03:26:54,380 : Building ./model/bge-large-zh tokenizer and model successfuly.
2023-08-22 03:26:54,382 : Loading kernel and bias from ./whiten/bge-large-zh-cls-whiten(NLI).pkl
2023-08-22 03:26:54,382 : ***** Transfer task : STS12 *****


2023-08-22 03:27:14,424 : MSRpar : pearson = 0.5261, spearman = 0.5235
2023-08-22 03:27:33,931 : MSRvid : pearson = 0.8626, spearman = 0.8577
2023-08-22 03:27:46,211 : SMTeuroparl : pearson = 0.5156, spearman = 0.5850
2023-08-22 03:28:06,612 : surprise.OnWN : pearson = 0.6953, spearman = 0.6737
2023-08-22 03:28:16,772 : surprise.SMTnews : pearson = 0.6135, spearman = 0.6049
2023-08-22 03:28:16,772 : ALL (weighted average) : Pearson = 0.6578,             Spearman = 0.6600
2023-08-22 03:28:16,772 : ALL (average) : Pearson = 0.6426,             Spearman = 0.6490

2023-08-22 03:28:16,772 : ***** Transfer task : STS13 (-SMT) *****


2023-08-22 03:28:21,956 : FNWN : pearson = 0.5043, spearman = 0.5278
2023-08-22 03:28:40,460 : headlines : pearson = 0.7735, spearman = 0.7609
2023-08-22 03:28:54,390 : OnWN : pearson = 0.7186, spearman = 0.7195
2023-08-22 03:28:54,390 : ALL (weighted average) : Pearson = 0.7190,             Spearman = 0.7160
2023-08-22 03:28:54,390 : ALL (average) : Pearson = 0.6654,             Spearman = 0.6694

2023-08-22 03:28:54,390 : ***** Transfer task : STS14 *****


2023-08-22 03:29:05,746 : deft-forum : pearson = 0.5896, spearman = 0.5775
2023-08-22 03:29:13,426 : deft-news : pearson = 0.8032, spearman = 0.7663
2023-08-22 03:29:32,392 : headlines : pearson = 0.7525, spearman = 0.7089
2023-08-22 03:29:51,148 : images : pearson = 0.8246, spearman = 0.7960
2023-08-22 03:30:09,854 : OnWN : pearson = 0.7883, spearman = 0.8019
2023-08-22 03:30:28,475 : tweet-news : pearson = 0.7957, spearman = 0.7268
2023-08-22 03:30:28,475 : ALL (weighted average) : Pearson = 0.7672,             Spearman = 0.7373
2023-08-22 03:30:28,475 : ALL (average) : Pearson = 0.7590,             Spearman = 0.7296

2023-08-22 03:30:28,475 : ***** Transfer task : STS15 *****


2023-08-22 03:30:37,726 : answers-forums : pearson = 0.7454, spearman = 0.7426
2023-08-22 03:30:56,045 : answers-students : pearson = 0.8030, spearman = 0.8157
2023-08-22 03:31:05,572 : belief : pearson = 0.8016, spearman = 0.8152
2023-08-22 03:31:24,046 : headlines : pearson = 0.7951, spearman = 0.7895
2023-08-22 03:31:43,228 : images : pearson = 0.8640, spearman = 0.8686
2023-08-22 03:31:43,228 : ALL (weighted average) : Pearson = 0.8089,             Spearman = 0.8132
2023-08-22 03:31:43,228 : ALL (average) : Pearson = 0.8018,             Spearman = 0.8063

2023-08-22 03:31:43,229 : ***** Transfer task : STS16 *****


2023-08-22 03:31:50,170 : answer-answer : pearson = 0.7201, spearman = 0.7172
2023-08-22 03:31:56,234 : headlines : pearson = 0.7998, spearman = 0.8129
2023-08-22 03:32:02,505 : plagiarism : pearson = 0.8346, spearman = 0.8430
2023-08-22 03:32:09,295 : postediting : pearson = 0.8611, spearman = 0.8723
2023-08-22 03:32:14,768 : question-question : pearson = 0.7142, spearman = 0.7154
2023-08-22 03:32:14,769 : ALL (weighted average) : Pearson = 0.7870,             Spearman = 0.7933
2023-08-22 03:32:14,769 : ALL (average) : Pearson = 0.7860,             Spearman = 0.7922

2023-08-22 03:32:14,769 : 

***** Transfer task : STSBenchmark*****


2023-08-22 03:32:14,869 : Computing embedding for test
2023-08-22 03:32:55,130 : Computed test embeddings
2023-08-22 03:32:55,211 : Test : Pearson 0.7547878594470343 Spearman 0.7443292002967626 MSE 6.147286105580263

2023-08-22 03:32:55,211 : ***** Transfer task : SICK-Relatedness*****


2023-08-22 03:32:55,244 : Computing embedding for test
2023-08-22 03:34:58,996 : Computed test embeddings
2023-08-22 03:34:59,197 : Test : Pearson 0.7089405271947513 Spearman 0.6688650976102345 MSE 9.596523557011176

2023-08-22 03:34:59,198 : BgeLarge-whiten-384(NLI)-cls results:
+----------------------+--------------------+
|         Task         |      Spearman      |
+----------------------+--------------------+
|        STS12         | 0.6599523905840493 |
|        STS13         | 0.7160299658440737 |
|        STS14         | 0.7373268081980607 |
|        STS15         | 0.8131938549308011 |
|        STS16         |  0.79327803332221  |
|  STSBenchmarkCosin   | 0.7443292002967626 |
| SICKRelatednessCosin | 0.6688650976102345 |
+----------------------+--------------------+
2023-08-22 03:34:59,205 : BgeLarge-whiten-1024(NLI)-first_last_avg configs: {'encoder': './model/bge-large-zh', 'pooling': 'first_last_avg', 'whiten_file': './whiten/bge-large-zh-first_last_avg-whiten(NLI).pkl', 'n_components': 1024}
2023-08-22 03:35:03,064 : Building ./model/bge-large-zh tokenizer and model successfuly.
2023-08-22 03:35:03,068 : Loading kernel and bias from ./whiten/bge-large-zh-first_last_avg-whiten(NLI).pkl
2023-08-22 03:35:03,068 : ***** Transfer task : STS12 *****


2023-08-22 03:35:22,291 : MSRpar : pearson = 0.3667, spearman = 0.3908
2023-08-22 03:35:41,325 : MSRvid : pearson = 0.8409, spearman = 0.8480
2023-08-22 03:35:52,489 : SMTeuroparl : pearson = 0.5020, spearman = 0.5787
2023-08-22 03:36:11,030 : surprise.OnWN : pearson = 0.6858, spearman = 0.6727
2023-08-22 03:36:20,715 : surprise.SMTnews : pearson = 0.5774, spearman = 0.5661
2023-08-22 03:36:20,716 : ALL (weighted average) : Pearson = 0.6052,             Spearman = 0.6194
2023-08-22 03:36:20,716 : ALL (average) : Pearson = 0.5946,             Spearman = 0.6113

2023-08-22 03:36:20,716 : ***** Transfer task : STS13 (-SMT) *****


2023-08-22 03:36:25,822 : FNWN : pearson = 0.4646, spearman = 0.5153
2023-08-22 03:36:43,785 : headlines : pearson = 0.7548, spearman = 0.7402
2023-08-22 03:36:57,403 : OnWN : pearson = 0.6835, spearman = 0.6804
2023-08-22 03:36:57,403 : ALL (weighted average) : Pearson = 0.6916,             Spearman = 0.6895
2023-08-22 03:36:57,404 : ALL (average) : Pearson = 0.6343,             Spearman = 0.6453

2023-08-22 03:36:57,404 : ***** Transfer task : STS14 *****


2023-08-22 03:37:08,530 : deft-forum : pearson = 0.5357, spearman = 0.5215
2023-08-22 03:37:16,380 : deft-news : pearson = 0.7651, spearman = 0.7166
2023-08-22 03:37:39,802 : headlines : pearson = 0.7311, spearman = 0.6895
2023-08-22 03:38:00,934 : images : pearson = 0.7827, spearman = 0.7749
2023-08-22 03:38:19,870 : OnWN : pearson = 0.7529, spearman = 0.7766
2023-08-22 03:38:38,663 : tweet-news : pearson = 0.7659, spearman = 0.7095
2023-08-22 03:38:38,663 : ALL (weighted average) : Pearson = 0.7320,             Spearman = 0.7100
2023-08-22 03:38:38,663 : ALL (average) : Pearson = 0.7222,             Spearman = 0.6981

2023-08-22 03:38:38,663 : ***** Transfer task : STS15 *****


2023-08-22 03:38:48,121 : answers-forums : pearson = 0.7192, spearman = 0.7215
2023-08-22 03:39:06,730 : answers-students : pearson = 0.7718, spearman = 0.7701
2023-08-22 03:39:16,181 : belief : pearson = 0.7391, spearman = 0.7669
2023-08-22 03:39:34,847 : headlines : pearson = 0.7852, spearman = 0.7809
2023-08-22 03:39:53,112 : images : pearson = 0.8232, spearman = 0.8414
2023-08-22 03:39:53,112 : ALL (weighted average) : Pearson = 0.7774,             Spearman = 0.7841
2023-08-22 03:39:53,112 : ALL (average) : Pearson = 0.7677,             Spearman = 0.7762

2023-08-22 03:39:53,112 : ***** Transfer task : STS16 *****


2023-08-22 03:39:59,201 : answer-answer : pearson = 0.6832, spearman = 0.6749
2023-08-22 03:40:05,265 : headlines : pearson = 0.7969, spearman = 0.7983
2023-08-22 03:40:10,856 : plagiarism : pearson = 0.8366, spearman = 0.8449
2023-08-22 03:40:17,000 : postediting : pearson = 0.8620, spearman = 0.8625
2023-08-22 03:40:22,010 : question-question : pearson = 0.5924, spearman = 0.5789
2023-08-22 03:40:22,010 : ALL (weighted average) : Pearson = 0.7576,             Spearman = 0.7554
2023-08-22 03:40:22,010 : ALL (average) : Pearson = 0.7542,             Spearman = 0.7519

2023-08-22 03:40:22,010 : 

***** Transfer task : STSBenchmark*****


2023-08-22 03:40:22,028 : Computing embedding for test
2023-08-22 03:40:55,347 : Computed test embeddings
2023-08-22 03:40:55,401 : Test : Pearson 0.7190458357902438 Spearman 0.706027347352962 MSE 6.514719011574194

2023-08-22 03:40:55,401 : ***** Transfer task : SICK-Relatedness*****


2023-08-22 03:40:55,421 : Computing embedding for test
2023-08-22 03:42:54,707 : Computed test embeddings
2023-08-22 03:42:54,917 : Test : Pearson 0.6652575690950153 Spearman 0.6428201026868314 MSE 10.102555254445955

2023-08-22 03:42:54,918 : BgeLarge-whiten-1024(NLI)-first_last_avg results:
+----------------------+--------------------+
|         Task         |      Spearman      |
+----------------------+--------------------+
|        STS12         | 0.6193982529742529 |
|        STS13         | 0.6894671254553923 |
|        STS14         | 0.7100182620169486 |
|        STS15         | 0.7841464966529557 |
|        STS16         | 0.7554432874962527 |
|  STSBenchmarkCosin   | 0.706027347352962  |
| SICKRelatednessCosin | 0.6428201026868314 |
+----------------------+--------------------+
2023-08-22 03:42:54,925 : BgeLarge-whiten-384(NLI)-first_last_avg configs: {'encoder': './model/bge-large-zh', 'pooling': 'first_last_avg', 'whiten_file': './whiten/bge-large-zh-first_last_avg-whiten(NLI).pkl', 'n_components': 384}
2023-08-22 03:42:57,273 : Building ./model/bge-large-zh tokenizer and model successfuly.
2023-08-22 03:42:57,274 : Loading kernel and bias from ./whiten/bge-large-zh-first_last_avg-whiten(NLI).pkl
2023-08-22 03:42:57,275 : ***** Transfer task : STS12 *****


2023-08-22 03:43:16,252 : MSRpar : pearson = 0.3587, spearman = 0.3907
2023-08-22 03:43:34,993 : MSRvid : pearson = 0.8528, spearman = 0.8479
2023-08-22 03:43:46,255 : SMTeuroparl : pearson = 0.5025, spearman = 0.5658
2023-08-22 03:44:04,855 : surprise.OnWN : pearson = 0.7048, spearman = 0.6943
2023-08-22 03:44:14,625 : surprise.SMTnews : pearson = 0.5907, spearman = 0.5706
2023-08-22 03:44:14,625 : ALL (weighted average) : Pearson = 0.6125,             Spearman = 0.6233
2023-08-22 03:44:14,625 : ALL (average) : Pearson = 0.6019,             Spearman = 0.6139

2023-08-22 03:44:14,625 : ***** Transfer task : STS13 (-SMT) *****


2023-08-22 03:44:19,700 : FNWN : pearson = 0.4580, spearman = 0.5048
2023-08-22 03:44:37,737 : headlines : pearson = 0.7579, spearman = 0.7461
2023-08-22 03:44:51,542 : OnWN : pearson = 0.6907, spearman = 0.6881
2023-08-22 03:44:51,543 : ALL (weighted average) : Pearson = 0.6950,             Spearman = 0.6940
2023-08-22 03:44:51,543 : ALL (average) : Pearson = 0.6355,             Spearman = 0.6463

2023-08-22 03:44:51,543 : ***** Transfer task : STS14 *****


2023-08-22 03:45:03,059 : deft-forum : pearson = 0.5382, spearman = 0.5253
2023-08-22 03:45:10,754 : deft-news : pearson = 0.7864, spearman = 0.7467
2023-08-22 03:45:29,378 : headlines : pearson = 0.7234, spearman = 0.6740
2023-08-22 03:45:48,339 : images : pearson = 0.8130, spearman = 0.7884
2023-08-22 03:46:07,243 : OnWN : pearson = 0.7708, spearman = 0.7919
2023-08-22 03:46:26,183 : tweet-news : pearson = 0.7909, spearman = 0.7204
2023-08-22 03:46:26,183 : ALL (weighted average) : Pearson = 0.7471,             Spearman = 0.7177
2023-08-22 03:46:26,183 : ALL (average) : Pearson = 0.7371,             Spearman = 0.7078

2023-08-22 03:46:26,183 : ***** Transfer task : STS15 *****


2023-08-22 03:46:35,683 : answers-forums : pearson = 0.6962, spearman = 0.6936
2023-08-22 03:46:54,555 : answers-students : pearson = 0.7889, spearman = 0.7928
2023-08-22 03:47:04,109 : belief : pearson = 0.7621, spearman = 0.7811
2023-08-22 03:47:22,683 : headlines : pearson = 0.7815, spearman = 0.7755
2023-08-22 03:47:41,768 : images : pearson = 0.8467, spearman = 0.8511
2023-08-22 03:47:41,768 : ALL (weighted average) : Pearson = 0.7866,             Spearman = 0.7892
2023-08-22 03:47:41,768 : ALL (average) : Pearson = 0.7751,             Spearman = 0.7788

2023-08-22 03:47:41,768 : ***** Transfer task : STS16 *****


2023-08-22 03:47:48,202 : answer-answer : pearson = 0.6826, spearman = 0.6805
2023-08-22 03:47:54,437 : headlines : pearson = 0.8046, spearman = 0.8133
2023-08-22 03:48:00,256 : plagiarism : pearson = 0.8266, spearman = 0.8313
2023-08-22 03:48:06,498 : postediting : pearson = 0.8598, spearman = 0.8672
2023-08-22 03:48:11,765 : question-question : pearson = 0.6470, spearman = 0.6341
2023-08-22 03:48:11,766 : ALL (weighted average) : Pearson = 0.7663,             Spearman = 0.7679
2023-08-22 03:48:11,766 : ALL (average) : Pearson = 0.7641,             Spearman = 0.7653

2023-08-22 03:48:11,766 : 

***** Transfer task : STSBenchmark*****


2023-08-22 03:48:11,864 : Computing embedding for test
2023-08-22 03:48:46,580 : Computed test embeddings
2023-08-22 03:48:46,628 : Test : Pearson 0.7284182582685207 Spearman 0.7139284533531542 MSE 6.244227196737666

2023-08-22 03:48:46,628 : ***** Transfer task : SICK-Relatedness*****


2023-08-22 03:48:46,648 : Computing embedding for test
2023-08-22 03:50:50,094 : Computed test embeddings
2023-08-22 03:50:50,285 : Test : Pearson 0.6891773799768887 Spearman 0.6450046982962427 MSE 9.71057216884433

2023-08-22 03:50:50,286 : BgeLarge-whiten-384(NLI)-first_last_avg results:
+----------------------+--------------------+
|         Task         |      Spearman      |
+----------------------+--------------------+
|        STS12         | 0.6232610237588347 |
|        STS13         | 0.6939860175258249 |
|        STS14         | 0.7176953270818466 |
|        STS15         | 0.7891914352858579 |
|        STS16         | 0.7678578226170908 |
|  STSBenchmarkCosin   | 0.7139284533531542 |
| SICKRelatednessCosin | 0.6450046982962427 |
+----------------------+--------------------+
