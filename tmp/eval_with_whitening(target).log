2023-08-22 03:50:52,805 : BgeBase-whiten-768(target)-cls configs: {'encoder': './model/bge-base-zh', 'pooling': 'cls', 'n_components': 768}
2023-08-22 03:50:56,675 : Building ./model/bge-base-zh tokenizer and model successfuly.
2023-08-22 03:50:56,675 : ***** Transfer task : STS12 *****


2023-08-22 03:51:39,936 : Get whiten kernel and bias from 6216 samples.
2023-08-22 03:51:50,274 : MSRpar : pearson = 0.5843, spearman = 0.5624
2023-08-22 03:52:00,622 : MSRvid : pearson = 0.8070, spearman = 0.8195
2023-08-22 03:52:06,878 : SMTeuroparl : pearson = 0.4704, spearman = 0.5727
2023-08-22 03:52:17,128 : surprise.OnWN : pearson = 0.6514, spearman = 0.6551
2023-08-22 03:52:22,634 : surprise.SMTnews : pearson = 0.4462, spearman = 0.5116
2023-08-22 03:52:22,634 : ALL (weighted average) : Pearson = 0.6197,             Spearman = 0.6418
2023-08-22 03:52:22,634 : ALL (average) : Pearson = 0.5918,             Spearman = 0.6243

2023-08-22 03:52:22,634 : ***** Transfer task : STS13 (-SMT) *****


2023-08-22 03:52:43,220 : Get whiten kernel and bias from 3000 samples.
2023-08-22 03:52:46,012 : FNWN : pearson = 0.3321, spearman = 0.3705
2023-08-22 03:52:56,589 : headlines : pearson = 0.7385, spearman = 0.7567
2023-08-22 03:53:04,258 : OnWN : pearson = 0.7494, spearman = 0.7534
2023-08-22 03:53:04,258 : ALL (weighted average) : Pearson = 0.6914,             Spearman = 0.7068
2023-08-22 03:53:04,258 : ALL (average) : Pearson = 0.6067,             Spearman = 0.6269

2023-08-22 03:53:04,258 : ***** Transfer task : STS14 *****


2023-08-22 03:53:56,781 : Get whiten kernel and bias from 7500 samples.
2023-08-22 03:54:03,064 : deft-forum : pearson = 0.4937, spearman = 0.4867
2023-08-22 03:54:07,307 : deft-news : pearson = 0.7356, spearman = 0.6953
2023-08-22 03:54:17,830 : headlines : pearson = 0.7286, spearman = 0.7259
2023-08-22 03:54:28,369 : images : pearson = 0.7697, spearman = 0.7776
2023-08-22 03:54:38,834 : OnWN : pearson = 0.7804, spearman = 0.8023
2023-08-22 03:54:49,215 : tweet-news : pearson = 0.7051, spearman = 0.6976
2023-08-22 03:54:49,215 : ALL (weighted average) : Pearson = 0.7148,             Spearman = 0.7147
2023-08-22 03:54:49,215 : ALL (average) : Pearson = 0.7022,             Spearman = 0.6976

2023-08-22 03:54:49,215 : ***** Transfer task : STS15 *****


2023-08-22 03:55:30,956 : Get whiten kernel and bias from 6000 samples.
2023-08-22 03:55:36,196 : answers-forums : pearson = 0.6995, spearman = 0.6953
2023-08-22 03:55:46,662 : answers-students : pearson = 0.6652, spearman = 0.7098
2023-08-22 03:55:51,785 : belief : pearson = 0.7427, spearman = 0.7586
2023-08-22 03:56:02,396 : headlines : pearson = 0.7697, spearman = 0.7904
2023-08-22 03:56:12,509 : images : pearson = 0.8037, spearman = 0.8215
2023-08-22 03:56:12,509 : ALL (weighted average) : Pearson = 0.7399,             Spearman = 0.7622
2023-08-22 03:56:12,509 : ALL (average) : Pearson = 0.7361,             Spearman = 0.7551

2023-08-22 03:56:12,509 : ***** Transfer task : STS16 *****


2023-08-22 03:56:29,054 : Get whiten kernel and bias from 2372 samples.
2023-08-22 03:56:32,579 : answer-answer : pearson = 0.5681, spearman = 0.5593
2023-08-22 03:56:36,085 : headlines : pearson = 0.7315, spearman = 0.7623
2023-08-22 03:56:39,301 : plagiarism : pearson = 0.6578, spearman = 0.7636
2023-08-22 03:56:42,787 : postediting : pearson = 0.8603, spearman = 0.8622
2023-08-22 03:56:45,713 : question-question : pearson = 0.6832, spearman = 0.7142
2023-08-22 03:56:45,713 : ALL (weighted average) : Pearson = 0.7002,             Spearman = 0.7312
2023-08-22 03:56:45,713 : ALL (average) : Pearson = 0.7002,             Spearman = 0.7323

2023-08-22 03:56:45,713 : ***** Transfer task : SICK-Relatedness*****


2023-08-22 03:59:06,001 : Get whiten kernel and bias from 19854 samples.
2023-08-22 03:59:06,002 : Computing embedding for test
2023-08-22 04:00:13,499 : Computed test embeddings
2023-08-22 04:00:13,694 : Test : Pearson 0.5790793243857068 Spearman 0.6029427556800969 MSE 10.609356508716248

2023-08-22 04:00:13,695 : 

***** Transfer task : STSBenchmark*****


2023-08-22 04:02:13,555 : Get whiten kernel and bias from 17256 samples.
2023-08-22 04:02:13,556 : Computing embedding for test
2023-08-22 04:02:32,734 : Computed test embeddings
2023-08-22 04:02:32,798 : Test : Pearson 0.6477340536326345 Spearman 0.6448429993180486 MSE 5.813899013398108

2023-08-22 04:02:32,799 : BgeBase-whiten-768(target)-cls results:
+----------------------+--------------------+
|         Task         |      Spearman      |
+----------------------+--------------------+
|        STS12         | 0.6418185270232997 |
|        STS13         | 0.7067975194949254 |
|        STS14         | 0.7147134675760716 |
|        STS15         | 0.7621735698311065 |
|        STS16         | 0.7311752721512779 |
| SICKRelatednessCosin | 0.6029427556800969 |
|  STSBenchmarkCosin   | 0.6448429993180486 |
+----------------------+--------------------+
2023-08-22 04:02:32,805 : BgeBase-whiten-256(target)-cls configs: {'encoder': './model/bge-base-zh', 'pooling': 'cls', 'n_components': 256}
2023-08-22 04:02:33,422 : Building ./model/bge-base-zh tokenizer and model successfuly.
2023-08-22 04:02:33,422 : ***** Transfer task : STS12 *****


2023-08-22 04:03:16,896 : Get whiten kernel and bias from 6216 samples.
2023-08-22 04:03:27,309 : MSRpar : pearson = 0.5672, spearman = 0.5351
2023-08-22 04:03:37,857 : MSRvid : pearson = 0.8421, spearman = 0.8343
2023-08-22 04:03:44,228 : SMTeuroparl : pearson = 0.5095, spearman = 0.5764
2023-08-22 04:03:54,698 : surprise.OnWN : pearson = 0.6847, spearman = 0.6661
2023-08-22 04:04:00,287 : surprise.SMTnews : pearson = 0.5187, spearman = 0.5243
2023-08-22 04:04:00,287 : ALL (weighted average) : Pearson = 0.6471,             Spearman = 0.6436
2023-08-22 04:04:00,287 : ALL (average) : Pearson = 0.6244,             Spearman = 0.6272

2023-08-22 04:04:00,287 : ***** Transfer task : STS13 (-SMT) *****


2023-08-22 04:04:21,355 : Get whiten kernel and bias from 3000 samples.
2023-08-22 04:04:24,024 : FNWN : pearson = 0.3687, spearman = 0.3978
2023-08-22 04:04:34,527 : headlines : pearson = 0.7740, spearman = 0.7694
2023-08-22 04:04:42,296 : OnWN : pearson = 0.7806, spearman = 0.7629
2023-08-22 04:04:42,297 : ALL (weighted average) : Pearson = 0.7254,             Spearman = 0.7201
2023-08-22 04:04:42,297 : ALL (average) : Pearson = 0.6411,             Spearman = 0.6433

2023-08-22 04:04:42,297 : ***** Transfer task : STS14 *****


2023-08-22 04:05:34,784 : Get whiten kernel and bias from 7500 samples.
2023-08-22 04:05:40,910 : deft-forum : pearson = 0.5057, spearman = 0.5067
2023-08-22 04:05:45,026 : deft-news : pearson = 0.7596, spearman = 0.7112
2023-08-22 04:05:55,553 : headlines : pearson = 0.7533, spearman = 0.7308
2023-08-22 04:06:05,842 : images : pearson = 0.8168, spearman = 0.7916
2023-08-22 04:06:16,244 : OnWN : pearson = 0.7966, spearman = 0.7987
2023-08-22 04:06:26,585 : tweet-news : pearson = 0.7424, spearman = 0.6919
2023-08-22 04:06:26,585 : ALL (weighted average) : Pearson = 0.7433,             Spearman = 0.7203
2023-08-22 04:06:26,585 : ALL (average) : Pearson = 0.7291,             Spearman = 0.7051

2023-08-22 04:06:26,585 : ***** Transfer task : STS15 *****


2023-08-22 04:07:07,885 : Get whiten kernel and bias from 6000 samples.
2023-08-22 04:07:13,373 : answers-forums : pearson = 0.6972, spearman = 0.6911
2023-08-22 04:07:23,494 : answers-students : pearson = 0.7228, spearman = 0.7322
2023-08-22 04:07:28,681 : belief : pearson = 0.7474, spearman = 0.7549
2023-08-22 04:07:38,792 : headlines : pearson = 0.8034, spearman = 0.8009
2023-08-22 04:07:49,276 : images : pearson = 0.8380, spearman = 0.8426
2023-08-22 04:07:49,276 : ALL (weighted average) : Pearson = 0.7716,             Spearman = 0.7747
2023-08-22 04:07:49,276 : ALL (average) : Pearson = 0.7618,             Spearman = 0.7643

2023-08-22 04:07:49,277 : ***** Transfer task : STS16 *****


2023-08-22 04:08:05,536 : Get whiten kernel and bias from 2372 samples.
2023-08-22 04:08:08,946 : answer-answer : pearson = 0.6244, spearman = 0.6182
2023-08-22 04:08:12,316 : headlines : pearson = 0.7785, spearman = 0.7802
2023-08-22 04:08:15,396 : plagiarism : pearson = 0.7922, spearman = 0.8135
2023-08-22 04:08:18,766 : postediting : pearson = 0.8522, spearman = 0.8611
2023-08-22 04:08:21,673 : question-question : pearson = 0.7126, spearman = 0.7109
2023-08-22 04:08:21,674 : ALL (weighted average) : Pearson = 0.7517,             Spearman = 0.7564
2023-08-22 04:08:21,674 : ALL (average) : Pearson = 0.7520,             Spearman = 0.7568

2023-08-22 04:08:21,674 : ***** Transfer task : SICK-Relatedness*****


2023-08-22 04:10:39,984 : Get whiten kernel and bias from 19854 samples.
2023-08-22 04:10:39,985 : Computing embedding for test
2023-08-22 04:11:47,031 : Computed test embeddings
2023-08-22 04:11:47,222 : Test : Pearson 0.6318778342765174 Spearman 0.5993102995273443 MSE 10.062459717737859

2023-08-22 04:11:47,223 : 

***** Transfer task : STSBenchmark*****


2023-08-22 04:13:46,425 : Get whiten kernel and bias from 17256 samples.
2023-08-22 04:13:46,425 : Computing embedding for test
2023-08-22 04:14:05,290 : Computed test embeddings
2023-08-22 04:14:05,343 : Test : Pearson 0.7490016212183288 Spearman 0.7371513395994013 MSE 6.277976343122132

2023-08-22 04:14:05,343 : BgeBase-whiten-256(target)-cls results:
+----------------------+--------------------+
|         Task         |      Spearman      |
+----------------------+--------------------+
|        STS12         | 0.643625826010409  |
|        STS13         | 0.7201350631587594 |
|        STS14         | 0.7202775007838932 |
|        STS15         | 0.7746703559830131 |
|        STS16         | 0.7563826003568381 |
| SICKRelatednessCosin | 0.5993102995273443 |
|  STSBenchmarkCosin   | 0.7371513395994013 |
+----------------------+--------------------+
2023-08-22 04:14:05,349 : BgeBase-whiten-768(target)-first_last_avg configs: {'encoder': './model/bge-base-zh', 'pooling': 'first_last_avg', 'n_components': 768}
2023-08-22 04:14:05,931 : Building ./model/bge-base-zh tokenizer and model successfuly.
2023-08-22 04:14:05,931 : ***** Transfer task : STS12 *****


2023-08-22 04:14:48,751 : Get whiten kernel and bias from 6216 samples.
2023-08-22 04:14:58,984 : MSRpar : pearson = 0.5892, spearman = 0.5662
2023-08-22 04:15:09,493 : MSRvid : pearson = 0.8024, spearman = 0.8190
2023-08-22 04:15:15,739 : SMTeuroparl : pearson = 0.4664, spearman = 0.5543
2023-08-22 04:15:26,064 : surprise.OnWN : pearson = 0.6723, spearman = 0.6726
2023-08-22 04:15:31,525 : surprise.SMTnews : pearson = 0.4629, spearman = 0.5372
2023-08-22 04:15:31,525 : ALL (weighted average) : Pearson = 0.6264,             Spearman = 0.6474
2023-08-22 04:15:31,525 : ALL (average) : Pearson = 0.5987,             Spearman = 0.6299

2023-08-22 04:15:31,525 : ***** Transfer task : STS13 (-SMT) *****


2023-08-22 04:15:52,256 : Get whiten kernel and bias from 3000 samples.
2023-08-22 04:15:54,833 : FNWN : pearson = 0.4329, spearman = 0.4520
2023-08-22 04:16:05,159 : headlines : pearson = 0.7387, spearman = 0.7551
2023-08-22 04:16:12,856 : OnWN : pearson = 0.7759, spearman = 0.7758
2023-08-22 04:16:12,856 : ALL (weighted average) : Pearson = 0.7141,             Spearman = 0.7246
2023-08-22 04:16:12,856 : ALL (average) : Pearson = 0.6491,             Spearman = 0.6610

2023-08-22 04:16:12,856 : ***** Transfer task : STS14 *****


2023-08-22 04:17:04,793 : Get whiten kernel and bias from 7500 samples.
2023-08-22 04:17:10,888 : deft-forum : pearson = 0.5318, spearman = 0.5201
2023-08-22 04:17:14,936 : deft-news : pearson = 0.7384, spearman = 0.6926
2023-08-22 04:17:25,506 : headlines : pearson = 0.7272, spearman = 0.7165
2023-08-22 04:17:35,662 : images : pearson = 0.7596, spearman = 0.7752
2023-08-22 04:17:46,188 : OnWN : pearson = 0.8045, spearman = 0.8186
2023-08-22 04:17:56,465 : tweet-news : pearson = 0.7320, spearman = 0.7157
2023-08-22 04:17:56,465 : ALL (weighted average) : Pearson = 0.7275,             Spearman = 0.7230
2023-08-22 04:17:56,465 : ALL (average) : Pearson = 0.7156,             Spearman = 0.7064

2023-08-22 04:17:56,465 : ***** Transfer task : STS15 *****


2023-08-22 04:18:38,002 : Get whiten kernel and bias from 6000 samples.
2023-08-22 04:18:43,308 : answers-forums : pearson = 0.6916, spearman = 0.6908
2023-08-22 04:18:53,443 : answers-students : pearson = 0.6741, spearman = 0.7218
2023-08-22 04:18:58,575 : belief : pearson = 0.7520, spearman = 0.7637
2023-08-22 04:19:08,894 : headlines : pearson = 0.7817, spearman = 0.7942
2023-08-22 04:19:19,274 : images : pearson = 0.7900, spearman = 0.8091
2023-08-22 04:19:19,275 : ALL (weighted average) : Pearson = 0.7419,             Spearman = 0.7631
2023-08-22 04:19:19,275 : ALL (average) : Pearson = 0.7379,             Spearman = 0.7559

2023-08-22 04:19:19,275 : ***** Transfer task : STS16 *****


2023-08-22 04:19:35,776 : Get whiten kernel and bias from 2372 samples.
2023-08-22 04:19:39,288 : answer-answer : pearson = 0.5723, spearman = 0.5786
2023-08-22 04:19:42,722 : headlines : pearson = 0.7525, spearman = 0.7854
2023-08-22 04:19:45,907 : plagiarism : pearson = 0.6476, spearman = 0.7157
2023-08-22 04:19:49,290 : postediting : pearson = 0.8782, spearman = 0.8776
2023-08-22 04:19:52,218 : question-question : pearson = 0.6800, spearman = 0.7121
2023-08-22 04:19:52,218 : ALL (weighted average) : Pearson = 0.7067,             Spearman = 0.7336
2023-08-22 04:19:52,218 : ALL (average) : Pearson = 0.7061,             Spearman = 0.7339

2023-08-22 04:19:52,218 : ***** Transfer task : SICK-Relatedness*****


2023-08-22 04:22:09,925 : Get whiten kernel and bias from 19854 samples.
2023-08-22 04:22:09,926 : Computing embedding for test
2023-08-22 04:23:17,868 : Computed test embeddings
2023-08-22 04:23:18,089 : Test : Pearson 0.561508282628509 Spearman 0.5897364640471324 MSE 10.919647765813538

2023-08-22 04:23:18,089 : 

***** Transfer task : STSBenchmark*****


2023-08-22 04:25:17,376 : Get whiten kernel and bias from 17256 samples.
2023-08-22 04:25:17,377 : Computing embedding for test
2023-08-22 04:25:36,180 : Computed test embeddings
2023-08-22 04:25:36,245 : Test : Pearson 0.7385021340961977 Spearman 0.734188363286351 MSE 6.74949126492007

2023-08-22 04:25:36,246 : BgeBase-whiten-768(target)-first_last_avg results:
+----------------------+--------------------+
|         Task         |      Spearman      |
+----------------------+--------------------+
|        STS12         | 0.647401998823551  |
|        STS13         | 0.7246478465700134 |
|        STS14         | 0.7229862985047784 |
|        STS15         | 0.7630965911643321 |
|        STS16         | 0.7336379564334099 |
| SICKRelatednessCosin | 0.5897364640471324 |
|  STSBenchmarkCosin   | 0.734188363286351  |
+----------------------+--------------------+
2023-08-22 04:25:36,252 : BgeBase-whiten-256(target)-first_last_avg configs: {'encoder': './model/bge-base-zh', 'pooling': 'first_last_avg', 'n_components': 256}
2023-08-22 04:25:36,780 : Building ./model/bge-base-zh tokenizer and model successfuly.
2023-08-22 04:25:36,780 : ***** Transfer task : STS12 *****


2023-08-22 04:26:19,606 : Get whiten kernel and bias from 6216 samples.
2023-08-22 04:26:30,099 : MSRpar : pearson = 0.5684, spearman = 0.5425
2023-08-22 04:26:40,207 : MSRvid : pearson = 0.8450, spearman = 0.8386
2023-08-22 04:26:46,558 : SMTeuroparl : pearson = 0.5188, spearman = 0.5907
2023-08-22 04:26:56,640 : surprise.OnWN : pearson = 0.7024, spearman = 0.6815
2023-08-22 04:27:02,031 : surprise.SMTnews : pearson = 0.5674, spearman = 0.5682
2023-08-22 04:27:02,032 : ALL (weighted average) : Pearson = 0.6600,             Spearman = 0.6579
2023-08-22 04:27:02,032 : ALL (average) : Pearson = 0.6404,             Spearman = 0.6443

2023-08-22 04:27:02,032 : ***** Transfer task : STS13 (-SMT) *****


2023-08-22 04:27:23,078 : Get whiten kernel and bias from 3000 samples.
2023-08-22 04:27:25,748 : FNWN : pearson = 0.3887, spearman = 0.4285
2023-08-22 04:27:36,168 : headlines : pearson = 0.7737, spearman = 0.7684
2023-08-22 04:27:43,876 : OnWN : pearson = 0.7978, spearman = 0.7761
2023-08-22 04:27:43,877 : ALL (weighted average) : Pearson = 0.7342,             Spearman = 0.7285
2023-08-22 04:27:43,877 : ALL (average) : Pearson = 0.6534,             Spearman = 0.6577

2023-08-22 04:27:43,877 : ***** Transfer task : STS14 *****


2023-08-22 04:28:35,824 : Get whiten kernel and bias from 7500 samples.
2023-08-22 04:28:42,141 : deft-forum : pearson = 0.5319, spearman = 0.5206
2023-08-22 04:28:46,339 : deft-news : pearson = 0.7682, spearman = 0.7215
2023-08-22 04:28:56,421 : headlines : pearson = 0.7421, spearman = 0.7124
2023-08-22 04:29:06,780 : images : pearson = 0.8199, spearman = 0.8043
2023-08-22 04:29:16,835 : OnWN : pearson = 0.8187, spearman = 0.8204
2023-08-22 04:29:27,347 : tweet-news : pearson = 0.7725, spearman = 0.7264
2023-08-22 04:29:27,347 : ALL (weighted average) : Pearson = 0.7559,             Spearman = 0.7329
2023-08-22 04:29:27,347 : ALL (average) : Pearson = 0.7422,             Spearman = 0.7176

2023-08-22 04:29:27,348 : ***** Transfer task : STS15 *****


2023-08-22 04:30:08,835 : Get whiten kernel and bias from 6000 samples.
2023-08-22 04:30:13,967 : answers-forums : pearson = 0.6947, spearman = 0.6848
2023-08-22 04:30:23,959 : answers-students : pearson = 0.7395, spearman = 0.7539
2023-08-22 04:30:29,222 : belief : pearson = 0.7615, spearman = 0.7660
2023-08-22 04:30:39,316 : headlines : pearson = 0.8010, spearman = 0.7970
2023-08-22 04:30:49,711 : images : pearson = 0.8296, spearman = 0.8329
2023-08-22 04:30:49,711 : ALL (weighted average) : Pearson = 0.7746,             Spearman = 0.7773
2023-08-22 04:30:49,712 : ALL (average) : Pearson = 0.7653,             Spearman = 0.7669

2023-08-22 04:30:49,712 : ***** Transfer task : STS16 *****


2023-08-22 04:31:05,821 : Get whiten kernel and bias from 2372 samples.
2023-08-22 04:31:09,295 : answer-answer : pearson = 0.6254, spearman = 0.6184
2023-08-22 04:31:12,693 : headlines : pearson = 0.7765, spearman = 0.7802
2023-08-22 04:31:15,840 : plagiarism : pearson = 0.7911, spearman = 0.8042
2023-08-22 04:31:19,145 : postediting : pearson = 0.8618, spearman = 0.8718
2023-08-22 04:31:21,996 : question-question : pearson = 0.7117, spearman = 0.7149
2023-08-22 04:31:21,996 : ALL (weighted average) : Pearson = 0.7531,             Spearman = 0.7575
2023-08-22 04:31:21,997 : ALL (average) : Pearson = 0.7533,             Spearman = 0.7579

2023-08-22 04:31:21,997 : ***** Transfer task : SICK-Relatedness*****


2023-08-22 04:33:37,712 : Get whiten kernel and bias from 19854 samples.
2023-08-22 04:33:37,712 : Computing embedding for test
2023-08-22 04:34:44,708 : Computed test embeddings
2023-08-22 04:34:44,888 : Test : Pearson 0.6285756477872204 Spearman 0.5939153107797888 MSE 10.051976420248605

2023-08-22 04:34:44,888 : 

***** Transfer task : STSBenchmark*****


2023-08-22 04:36:42,906 : Get whiten kernel and bias from 17256 samples.
2023-08-22 04:36:42,907 : Computing embedding for test
2023-08-22 04:37:01,495 : Computed test embeddings
2023-08-22 04:37:01,553 : Test : Pearson 0.7446210046091126 Spearman 0.7334631204796355 MSE 6.2948823084537375

2023-08-22 04:37:01,554 : BgeBase-whiten-256(target)-first_last_avg results:
+----------------------+--------------------+
|         Task         |      Spearman      |
+----------------------+--------------------+
|        STS12         | 0.6579071134811959 |
|        STS13         | 0.7284560082718362 |
|        STS14         | 0.7329020285383886 |
|        STS15         | 0.7773188855170005 |
|        STS16         | 0.7575187275020387 |
| SICKRelatednessCosin | 0.5939153107797888 |
|  STSBenchmarkCosin   | 0.7334631204796355 |
+----------------------+--------------------+
2023-08-22 04:37:01,562 : BgeLarge-whiten-1024(target)-cls configs: {'encoder': './model/bge-large-zh', 'pooling': 'cls', 'n_components': 1024}
2023-08-22 04:37:04,096 : Building ./model/bge-large-zh tokenizer and model successfuly.
2023-08-22 04:37:04,096 : ***** Transfer task : STS12 *****


2023-08-22 04:38:22,825 : Get whiten kernel and bias from 6216 samples.
2023-08-22 04:38:42,209 : MSRpar : pearson = 0.6288, spearman = 0.5927
2023-08-22 04:39:01,285 : MSRvid : pearson = 0.8127, spearman = 0.8361
2023-08-22 04:39:12,833 : SMTeuroparl : pearson = 0.4515, spearman = 0.5571
2023-08-22 04:39:31,769 : surprise.OnWN : pearson = 0.6733, spearman = 0.6807
2023-08-22 04:39:41,703 : surprise.SMTnews : pearson = 0.4508, spearman = 0.5500
2023-08-22 04:39:41,703 : ALL (weighted average) : Pearson = 0.6349,             Spearman = 0.6619
2023-08-22 04:39:41,703 : ALL (average) : Pearson = 0.6034,             Spearman = 0.6433

2023-08-22 04:39:41,704 : ***** Transfer task : STS13 (-SMT) *****


2023-08-22 04:40:20,226 : Get whiten kernel and bias from 3000 samples.
2023-08-22 04:40:25,422 : FNWN : pearson = 0.4612, spearman = 0.5191
2023-08-22 04:40:44,144 : headlines : pearson = 0.7424, spearman = 0.7697
2023-08-22 04:40:58,461 : OnWN : pearson = 0.7760, spearman = 0.7909
2023-08-22 04:40:58,461 : ALL (weighted average) : Pearson = 0.7195,             Spearman = 0.7460
2023-08-22 04:40:58,461 : ALL (average) : Pearson = 0.6599,             Spearman = 0.6932

2023-08-22 04:40:58,461 : ***** Transfer task : STS14 *****


2023-08-22 04:42:33,998 : Get whiten kernel and bias from 7500 samples.
2023-08-22 04:42:45,459 : deft-forum : pearson = 0.5418, spearman = 0.5229
2023-08-22 04:42:53,221 : deft-news : pearson = 0.7484, spearman = 0.7234
2023-08-22 04:43:11,919 : headlines : pearson = 0.7604, spearman = 0.7518
2023-08-22 04:43:30,812 : images : pearson = 0.7486, spearman = 0.7771
2023-08-22 04:43:49,704 : OnWN : pearson = 0.8137, spearman = 0.8363
2023-08-22 04:44:08,515 : tweet-news : pearson = 0.7232, spearman = 0.7204
2023-08-22 04:44:08,515 : ALL (weighted average) : Pearson = 0.7341,             Spearman = 0.7377
2023-08-22 04:44:08,516 : ALL (average) : Pearson = 0.7227,             Spearman = 0.7220

2023-08-22 04:44:08,516 : ***** Transfer task : STS15 *****


2023-08-22 04:45:24,855 : Get whiten kernel and bias from 6000 samples.
2023-08-22 04:45:34,094 : answers-forums : pearson = 0.7331, spearman = 0.7360
2023-08-22 04:45:52,959 : answers-students : pearson = 0.6918, spearman = 0.6963
2023-08-22 04:46:02,724 : belief : pearson = 0.7703, spearman = 0.7837
2023-08-22 04:46:21,540 : headlines : pearson = 0.7929, spearman = 0.8087
2023-08-22 04:46:40,561 : images : pearson = 0.8099, spearman = 0.8273
2023-08-22 04:46:40,561 : ALL (weighted average) : Pearson = 0.7616,             Spearman = 0.7730
2023-08-22 04:46:40,561 : ALL (average) : Pearson = 0.7596,             Spearman = 0.7704

2023-08-22 04:46:40,561 : ***** Transfer task : STS16 *****


2023-08-22 04:47:10,446 : Get whiten kernel and bias from 2372 samples.
2023-08-22 04:47:17,044 : answer-answer : pearson = 0.6024, spearman = 0.6017
2023-08-22 04:47:23,236 : headlines : pearson = 0.7698, spearman = 0.8139
2023-08-22 04:47:28,938 : plagiarism : pearson = 0.4746, spearman = 0.4508
2023-08-22 04:47:35,411 : postediting : pearson = 0.8231, spearman = 0.8371
2023-08-22 04:47:40,621 : question-question : pearson = 0.6016, spearman = 0.5899
2023-08-22 04:47:40,621 : ALL (weighted average) : Pearson = 0.6580,             Spearman = 0.6633
2023-08-22 04:47:40,621 : ALL (average) : Pearson = 0.6543,             Spearman = 0.6587

2023-08-22 04:47:40,621 : ***** Transfer task : SICK-Relatedness*****


2023-08-22 04:51:54,186 : Get whiten kernel and bias from 19854 samples.
2023-08-22 04:51:54,187 : Computing embedding for test
2023-08-22 04:53:59,097 : Computed test embeddings
2023-08-22 04:53:59,310 : Test : Pearson 0.5765076901371198 Spearman 0.5969159578189855 MSE 9.53019661967392

2023-08-22 04:53:59,311 : 

***** Transfer task : STSBenchmark*****


2023-08-22 04:57:40,051 : Get whiten kernel and bias from 17256 samples.
2023-08-22 04:57:40,051 : Computing embedding for test
2023-08-22 04:58:14,842 : Computed test embeddings
2023-08-22 04:58:14,913 : Test : Pearson 0.7621068166818241 Spearman 0.7634175100614461 MSE 6.775930028079262

2023-08-22 04:58:14,913 : BgeLarge-whiten-1024(target)-cls results:
+----------------------+--------------------+
|         Task         |      Spearman      |
+----------------------+--------------------+
|        STS12         | 0.6619477986632262 |
|        STS13         | 0.7460281646477097 |
|        STS14         | 0.737712388099552  |
|        STS15         | 0.7730291866493121 |
|        STS16         | 0.6633441324998307 |
| SICKRelatednessCosin | 0.5969159578189855 |
|  STSBenchmarkCosin   | 0.7634175100614461 |
+----------------------+--------------------+
2023-08-22 04:58:14,919 : BgeLarge-whiten-384(target)-cls configs: {'encoder': './model/bge-large-zh', 'pooling': 'cls', 'n_components': 384}
2023-08-22 04:58:16,904 : Building ./model/bge-large-zh tokenizer and model successfuly.
2023-08-22 04:58:16,905 : ***** Transfer task : STS12 *****


2023-08-22 04:59:36,115 : Get whiten kernel and bias from 6216 samples.
2023-08-22 04:59:55,304 : MSRpar : pearson = 0.6337, spearman = 0.5937
2023-08-22 05:00:14,211 : MSRvid : pearson = 0.8577, spearman = 0.8518
2023-08-22 05:00:25,634 : SMTeuroparl : pearson = 0.4842, spearman = 0.5587
2023-08-22 05:00:44,557 : surprise.OnWN : pearson = 0.7112, spearman = 0.6849
2023-08-22 05:00:54,746 : surprise.SMTnews : pearson = 0.5684, spearman = 0.5677
2023-08-22 05:00:54,746 : ALL (weighted average) : Pearson = 0.6760,             Spearman = 0.6695
2023-08-22 05:00:54,747 : ALL (average) : Pearson = 0.6510,             Spearman = 0.6514

2023-08-22 05:00:54,747 : ***** Transfer task : STS13 (-SMT) *****


2023-08-22 05:01:33,221 : Get whiten kernel and bias from 3000 samples.
2023-08-22 05:01:38,431 : FNWN : pearson = 0.4618, spearman = 0.4809
2023-08-22 05:01:57,152 : headlines : pearson = 0.7994, spearman = 0.7933
2023-08-22 05:02:11,175 : OnWN : pearson = 0.8198, spearman = 0.8010
2023-08-22 05:02:11,175 : ALL (weighted average) : Pearson = 0.7645,             Spearman = 0.7568
2023-08-22 05:02:11,175 : ALL (average) : Pearson = 0.6937,             Spearman = 0.6918

2023-08-22 05:02:11,175 : ***** Transfer task : STS14 *****


2023-08-22 05:03:46,464 : Get whiten kernel and bias from 7500 samples.
2023-08-22 05:03:57,941 : deft-forum : pearson = 0.5707, spearman = 0.5601
2023-08-22 05:04:05,757 : deft-news : pearson = 0.7825, spearman = 0.7478
2023-08-22 05:04:24,636 : headlines : pearson = 0.7786, spearman = 0.7518
2023-08-22 05:04:43,507 : images : pearson = 0.8110, spearman = 0.8000
2023-08-22 05:05:02,376 : OnWN : pearson = 0.8484, spearman = 0.8397
2023-08-22 05:05:21,189 : tweet-news : pearson = 0.7701, spearman = 0.7281
2023-08-22 05:05:21,189 : ALL (weighted average) : Pearson = 0.7727,             Spearman = 0.7510
2023-08-22 05:05:21,190 : ALL (average) : Pearson = 0.7602,             Spearman = 0.7379

2023-08-22 05:05:21,190 : ***** Transfer task : STS15 *****


2023-08-22 05:06:37,354 : Get whiten kernel and bias from 6000 samples.
2023-08-22 05:06:46,938 : answers-forums : pearson = 0.7508, spearman = 0.7495
2023-08-22 05:07:05,718 : answers-students : pearson = 0.7782, spearman = 0.7975
2023-08-22 05:07:15,006 : belief : pearson = 0.7901, spearman = 0.7965
2023-08-22 05:07:33,907 : headlines : pearson = 0.8223, spearman = 0.8202
2023-08-22 05:07:52,824 : images : pearson = 0.8347, spearman = 0.8409
2023-08-22 05:07:52,825 : ALL (weighted average) : Pearson = 0.8014,             Spearman = 0.8079
2023-08-22 05:07:52,825 : ALL (average) : Pearson = 0.7952,             Spearman = 0.8009

2023-08-22 05:07:52,825 : ***** Transfer task : STS16 *****


2023-08-22 05:08:23,195 : Get whiten kernel and bias from 2372 samples.
2023-08-22 05:08:29,504 : answer-answer : pearson = 0.6855, spearman = 0.6897
2023-08-22 05:08:35,836 : headlines : pearson = 0.8254, spearman = 0.8293
2023-08-22 05:08:41,717 : plagiarism : pearson = 0.7804, spearman = 0.8142
2023-08-22 05:08:47,991 : postediting : pearson = 0.8704, spearman = 0.8795
2023-08-22 05:08:53,153 : question-question : pearson = 0.7525, spearman = 0.7557
2023-08-22 05:08:53,154 : ALL (weighted average) : Pearson = 0.7831,             Spearman = 0.7938
2023-08-22 05:08:53,154 : ALL (average) : Pearson = 0.7828,             Spearman = 0.7937

2023-08-22 05:08:53,154 : ***** Transfer task : SICK-Relatedness*****


2023-08-22 05:13:06,708 : Get whiten kernel and bias from 19854 samples.
2023-08-22 05:13:06,709 : Computing embedding for test
2023-08-22 05:15:11,196 : Computed test embeddings
2023-08-22 05:15:11,398 : Test : Pearson 0.6468618849683234 Spearman 0.6356285962105958 MSE 10.195038095252908

2023-08-22 05:15:11,399 : 

***** Transfer task : STSBenchmark*****


2023-08-22 05:18:51,523 : Get whiten kernel and bias from 17256 samples.
2023-08-22 05:18:51,524 : Computing embedding for test
2023-08-22 05:19:26,345 : Computed test embeddings
2023-08-22 05:19:26,421 : Test : Pearson 0.7832940929441106 Spearman 0.7756206392622119 MSE 6.2876287717889845

2023-08-22 05:19:26,421 : BgeLarge-whiten-384(target)-cls results:
+----------------------+--------------------+
|         Task         |      Spearman      |
+----------------------+--------------------+
|        STS12         | 0.6694822638689862 |
|        STS13         | 0.7568363609957521 |
|        STS14         | 0.750957870984283  |
|        STS15         | 0.8078799281390427 |
|        STS16         | 0.7938306704963364 |
| SICKRelatednessCosin | 0.6356285962105958 |
|  STSBenchmarkCosin   | 0.7756206392622119 |
+----------------------+--------------------+
2023-08-22 05:19:26,429 : BgeLarge-whiten-1024(target)-first_last_avg configs: {'encoder': './model/bge-large-zh', 'pooling': 'first_last_avg', 'n_components': 1024}
2023-08-22 05:19:28,003 : Building ./model/bge-large-zh tokenizer and model successfuly.
2023-08-22 05:19:28,004 : ***** Transfer task : STS12 *****


2023-08-22 05:20:47,468 : Get whiten kernel and bias from 6216 samples.
2023-08-22 05:21:06,669 : MSRpar : pearson = 0.5605, spearman = 0.5208
2023-08-22 05:21:25,954 : MSRvid : pearson = 0.8006, spearman = 0.8279
2023-08-22 05:21:37,532 : SMTeuroparl : pearson = 0.4373, spearman = 0.5379
2023-08-22 05:21:56,501 : surprise.OnWN : pearson = 0.6810, spearman = 0.6900
2023-08-22 05:22:06,547 : surprise.SMTnews : pearson = 0.4382, spearman = 0.5455
2023-08-22 05:22:06,547 : ALL (weighted average) : Pearson = 0.6136,             Spearman = 0.6414
2023-08-22 05:22:06,547 : ALL (average) : Pearson = 0.5835,             Spearman = 0.6244

2023-08-22 05:22:06,547 : ***** Transfer task : STS13 (-SMT) *****


2023-08-22 05:22:45,154 : Get whiten kernel and bias from 3000 samples.
2023-08-22 05:22:50,399 : FNWN : pearson = 0.3900, spearman = 0.3772
2023-08-22 05:23:09,149 : headlines : pearson = 0.7318, spearman = 0.7590
2023-08-22 05:23:23,440 : OnWN : pearson = 0.7806, spearman = 0.7864
2023-08-22 05:23:23,440 : ALL (weighted average) : Pearson = 0.7070,             Spearman = 0.7211
2023-08-22 05:23:23,440 : ALL (average) : Pearson = 0.6341,             Spearman = 0.6408

2023-08-22 05:23:23,440 : ***** Transfer task : STS14 *****


2023-08-22 05:24:59,066 : Get whiten kernel and bias from 7500 samples.
2023-08-22 05:25:10,593 : deft-forum : pearson = 0.5193, spearman = 0.5054
2023-08-22 05:25:18,228 : deft-news : pearson = 0.7091, spearman = 0.6817
2023-08-22 05:25:37,100 : headlines : pearson = 0.7444, spearman = 0.7394
2023-08-22 05:25:56,262 : images : pearson = 0.7404, spearman = 0.7679
2023-08-22 05:26:15,246 : OnWN : pearson = 0.8188, spearman = 0.8342
2023-08-22 05:26:34,121 : tweet-news : pearson = 0.7220, spearman = 0.7167
2023-08-22 05:26:34,121 : ALL (weighted average) : Pearson = 0.7242,             Spearman = 0.7268
2023-08-22 05:26:34,121 : ALL (average) : Pearson = 0.7090,             Spearman = 0.7076

2023-08-22 05:26:34,121 : ***** Transfer task : STS15 *****


2023-08-22 05:27:50,203 : Get whiten kernel and bias from 6000 samples.
2023-08-22 05:27:59,745 : answers-forums : pearson = 0.7189, spearman = 0.7270
2023-08-22 05:28:18,543 : answers-students : pearson = 0.6813, spearman = 0.7371
2023-08-22 05:28:27,882 : belief : pearson = 0.7254, spearman = 0.7583
2023-08-22 05:28:46,890 : headlines : pearson = 0.7873, spearman = 0.8046
2023-08-22 05:29:05,889 : images : pearson = 0.7754, spearman = 0.8068
2023-08-22 05:29:05,889 : ALL (weighted average) : Pearson = 0.7416,             Spearman = 0.7728
2023-08-22 05:29:05,889 : ALL (average) : Pearson = 0.7377,             Spearman = 0.7668

2023-08-22 05:29:05,890 : ***** Transfer task : STS16 *****


2023-08-22 05:29:36,296 : Get whiten kernel and bias from 2372 samples.
2023-08-22 05:29:42,587 : answer-answer : pearson = 0.5598, spearman = 0.5840
2023-08-22 05:29:48,984 : headlines : pearson = 0.7423, spearman = 0.8071
2023-08-22 05:29:54,808 : plagiarism : pearson = 0.5817, spearman = 0.7034
2023-08-22 05:30:01,078 : postediting : pearson = 0.8640, spearman = 0.8734
2023-08-22 05:30:06,427 : question-question : pearson = 0.6698, spearman = 0.7268
2023-08-22 05:30:06,427 : ALL (weighted average) : Pearson = 0.6843,             Spearman = 0.7387
2023-08-22 05:30:06,427 : ALL (average) : Pearson = 0.6835,             Spearman = 0.7389

2023-08-22 05:30:06,427 : ***** Transfer task : SICK-Relatedness*****


2023-08-22 05:34:21,935 : Get whiten kernel and bias from 19854 samples.
2023-08-22 05:34:21,936 : Computing embedding for test
2023-08-22 05:36:26,793 : Computed test embeddings
2023-08-22 05:36:27,016 : Test : Pearson 0.5647584270588433 Spearman 0.6051642930207136 MSE 11.17352635729133

2023-08-22 05:36:27,017 : 

***** Transfer task : STSBenchmark*****


2023-08-22 05:40:06,738 : Get whiten kernel and bias from 17256 samples.
2023-08-22 05:40:06,739 : Computing embedding for test
2023-08-22 05:40:41,651 : Computed test embeddings
2023-08-22 05:40:41,705 : Test : Pearson 0.7405251804073387 Spearman 0.7378006337348975 MSE 6.834867525717195

2023-08-22 05:40:41,705 : BgeLarge-whiten-1024(target)-first_last_avg results:
+----------------------+--------------------+
|         Task         |      Spearman      |
+----------------------+--------------------+
|        STS12         | 0.6414425000989853 |
|        STS13         | 0.7211180705049287 |
|        STS14         | 0.7268288089596494 |
|        STS15         | 0.7727802179238968 |
|        STS16         | 0.7386972692342847 |
| SICKRelatednessCosin | 0.6051642930207136 |
|  STSBenchmarkCosin   | 0.7378006337348975 |
+----------------------+--------------------+
2023-08-22 05:40:41,712 : BgeLarge-whiten-384(target)-first_last_avg configs: {'encoder': './model/bge-large-zh', 'pooling': 'first_last_avg', 'n_components': 384}
2023-08-22 05:40:43,285 : Building ./model/bge-large-zh tokenizer and model successfuly.
2023-08-22 05:40:43,285 : ***** Transfer task : STS12 *****


2023-08-22 05:42:02,504 : Get whiten kernel and bias from 6216 samples.
2023-08-22 05:42:21,662 : MSRpar : pearson = 0.5396, spearman = 0.5071
2023-08-22 05:42:40,897 : MSRvid : pearson = 0.8468, spearman = 0.8428
2023-08-22 05:42:52,481 : SMTeuroparl : pearson = 0.4809, spearman = 0.5509
2023-08-22 05:43:11,453 : surprise.OnWN : pearson = 0.7178, spearman = 0.6968
2023-08-22 05:43:21,591 : surprise.SMTnews : pearson = 0.5705, spearman = 0.5637
2023-08-22 05:43:21,591 : ALL (weighted average) : Pearson = 0.6520,             Spearman = 0.6476
2023-08-22 05:43:21,591 : ALL (average) : Pearson = 0.6311,             Spearman = 0.6322

2023-08-22 05:43:21,591 : ***** Transfer task : STS13 (-SMT) *****


2023-08-22 05:44:00,377 : Get whiten kernel and bias from 3000 samples.
2023-08-22 05:44:05,650 : FNWN : pearson = 0.4685, spearman = 0.5026
2023-08-22 05:44:24,399 : headlines : pearson = 0.7849, spearman = 0.7789
2023-08-22 05:44:38,548 : OnWN : pearson = 0.8190, spearman = 0.7905
2023-08-22 05:44:38,548 : ALL (weighted average) : Pearson = 0.7578,             Spearman = 0.7485
2023-08-22 05:44:38,548 : ALL (average) : Pearson = 0.6908,             Spearman = 0.6907

2023-08-22 05:44:38,549 : ***** Transfer task : STS14 *****


2023-08-22 05:46:13,722 : Get whiten kernel and bias from 7500 samples.
2023-08-22 05:46:25,326 : deft-forum : pearson = 0.5304, spearman = 0.5168
2023-08-22 05:46:32,884 : deft-news : pearson = 0.7609, spearman = 0.7252
2023-08-22 05:46:51,767 : headlines : pearson = 0.7557, spearman = 0.7246
2023-08-22 05:47:10,791 : images : pearson = 0.8083, spearman = 0.8000
2023-08-22 05:47:29,937 : OnWN : pearson = 0.8386, spearman = 0.8369
2023-08-22 05:47:48,843 : tweet-news : pearson = 0.7770, spearman = 0.7360
2023-08-22 05:47:48,843 : ALL (weighted average) : Pearson = 0.7604,             Spearman = 0.7395
2023-08-22 05:47:48,843 : ALL (average) : Pearson = 0.7451,             Spearman = 0.7233

2023-08-22 05:47:48,843 : ***** Transfer task : STS15 *****


2023-08-22 05:49:04,732 : Get whiten kernel and bias from 6000 samples.
2023-08-22 05:49:14,310 : answers-forums : pearson = 0.6980, spearman = 0.6999
2023-08-22 05:49:33,221 : answers-students : pearson = 0.7503, spearman = 0.7750
2023-08-22 05:49:42,663 : belief : pearson = 0.7550, spearman = 0.7755
2023-08-22 05:50:01,464 : headlines : pearson = 0.8081, spearman = 0.8041
2023-08-22 05:50:20,666 : images : pearson = 0.8175, spearman = 0.8254
2023-08-22 05:50:20,666 : ALL (weighted average) : Pearson = 0.7756,             Spearman = 0.7856
2023-08-22 05:50:20,666 : ALL (average) : Pearson = 0.7658,             Spearman = 0.7760

2023-08-22 05:50:20,666 : ***** Transfer task : STS16 *****


2023-08-22 05:50:51,271 : Get whiten kernel and bias from 2372 samples.
2023-08-22 05:50:57,530 : answer-answer : pearson = 0.6464, spearman = 0.6444
2023-08-22 05:51:03,822 : headlines : pearson = 0.8218, spearman = 0.8230
2023-08-22 05:51:09,636 : plagiarism : pearson = 0.7518, spearman = 0.7740
2023-08-22 05:51:15,885 : postediting : pearson = 0.8706, spearman = 0.8783
2023-08-22 05:51:21,135 : question-question : pearson = 0.7373, spearman = 0.7432
2023-08-22 05:51:21,135 : ALL (weighted average) : Pearson = 0.7658,             Spearman = 0.7726
2023-08-22 05:51:21,136 : ALL (average) : Pearson = 0.7656,             Spearman = 0.7726

2023-08-22 05:51:21,136 : ***** Transfer task : SICK-Relatedness*****


2023-08-22 05:55:35,124 : Get whiten kernel and bias from 19854 samples.
2023-08-22 05:55:35,124 : Computing embedding for test
2023-08-22 05:57:39,355 : Computed test embeddings
2023-08-22 05:57:39,536 : Test : Pearson 0.6293430249246816 Spearman 0.6139644529584661 MSE 10.239293158725683

2023-08-22 05:57:39,537 : 

***** Transfer task : STSBenchmark*****


2023-08-22 06:01:18,627 : Get whiten kernel and bias from 17256 samples.
2023-08-22 06:01:18,628 : Computing embedding for test
2023-08-22 06:01:52,550 : Computed test embeddings
2023-08-22 06:01:52,598 : Test : Pearson 0.7573699562067784 Spearman 0.7486125358405785 MSE 6.379271998618779

2023-08-22 06:01:52,599 : BgeLarge-whiten-384(target)-first_last_avg results:
+----------------------+--------------------+
|         Task         |      Spearman      |
+----------------------+--------------------+
|        STS12         | 0.6476014092536265 |
|        STS13         | 0.7484571540522611 |
|        STS14         | 0.7395413050262767 |
|        STS15         | 0.7855512184790908 |
|        STS16         | 0.7725572125313923 |
| SICKRelatednessCosin | 0.6139644529584661 |
|  STSBenchmarkCosin   | 0.7486125358405785 |
+----------------------+--------------------+
